
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import precision_score, recall_score, f1_score

# æœºå™¨å­¦ä¹ æ¨¡å‹
from sklearn.linear_model import LogisticRegression, Ridge, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, \
    ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier


import warnings

warnings.filterwarnings('ignore')
######################################
#1ä¿®æ”¹ç›®æ ‡å˜é‡
#2ä¿®æ”¹ä¿å­˜çš„æ–‡ä»¶åï¼ŒæŒ‰ç…§åºå·ä¾æ¬¡å¯¹åº”ï¼Œ['ç–²åŠ³åˆ†ç±»æ ‡ç­¾', 'è¡€ç³–åˆ†ç±»æ ‡ç­¾', 'æ°´åˆçŠ¶æ€åˆ†ç±»æ ‡ç­¾', 'ä¹³é…¸åˆ†ç±»æ ‡ç­¾', 'è‚Œè‚‰ç–²åŠ³åˆ†ç±»æ ‡ç­¾', 'è›‹ç™½ä¾›åº”åˆ†ç±»æ ‡ç­¾']['ç–²åŠ³åˆ†ç±»æ ‡ç­¾', 'è¡€ç³–åˆ†ç±»æ ‡ç­¾', 'æ°´åˆçŠ¶æ€åˆ†ç±»æ ‡ç­¾', 'ä¹³é…¸åˆ†ç±»æ ‡ç­¾', 'è‚Œè‚‰ç–²åŠ³åˆ†ç±»æ ‡ç­¾', 'è›‹ç™½ä¾›åº”åˆ†ç±»æ ‡ç­¾']
####################################
num = 5  #è‡ªè¡Œä¿®æ”¹
# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']  # æ˜¾ç¤ºä¸­æ–‡
pd.set_option('display.max_columns', None)  # æ˜¾ç¤ºæ‰€æœ‰åˆ—
pd.set_option('display.max_rows', None)     # æ˜¾ç¤ºæ‰€æœ‰è¡Œ

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

print("=" * 80)
print("æœºå™¨å­¦ä¹ å®Œæ•´Pipeline: EDA â†’ é¢„å¤„ç† â†’ æ¨¡å‹å¯¹æ¯” â†’ æœ€ä¼˜é€‰æ‹©")
print("=" * 80)

# 1. æ•°æ®åŠ è½½å’Œå‡†å¤‡
print("\n1. æ•°æ®åŠ è½½å’Œå‡†å¤‡")
print("-" * 50)

# è¯»å–æ•°æ®

data = pd.read_excel('2025_9_20_filled_data_linear_interpolation.xlsx')
print("âœ“ ä½¿ç”¨å¡«å……åçš„æ•°æ®")

print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(data.columns)
# å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡
feature_cols = ['æ€§åˆ«','Na (mM)', 'K (mM)', 'Glucose (uM)',
       'Lactate (mM)', 'SUN (mM)', 'NH4 (mM)', 'Cortisol', 'Tes', 'MDF', 'MEF']
feature_cols = [col for col in feature_cols if col in data.columns]

target_cols = [col for col in data.columns if 'åˆ†ç±»æ ‡ç­¾' in col]
print(f"ç‰¹å¾å˜é‡: {feature_cols}")
print(f"ç›®æ ‡å˜é‡: {target_cols}")

# åˆ†åˆ«é€‰æ‹©6ä¸ªç›®æ ‡å˜é‡: ['ç–²åŠ³åˆ†ç±»æ ‡ç­¾', 'è¡€ç³–åˆ†ç±»æ ‡ç­¾', 'æ°´åˆçŠ¶æ€åˆ†ç±»æ ‡ç­¾', 'ä¹³é…¸åˆ†ç±»æ ‡ç­¾', 'è‚Œè‚‰ç–²åŠ³åˆ†ç±»æ ‡ç­¾', 'è›‹ç™½ä¾›åº”åˆ†ç±»æ ‡ç­¾']è¿›è¡Œå»ºæ¨¡
main_target = 'è‚Œè‚‰ç–²åŠ³åˆ†ç±»æ ‡ç­¾'  # å¯æ ¹æ®éœ€è¦æ›´æ”¹ç›®æ ‡å˜é‡
if main_target not in data.columns:
    raise ValueError(f"ç›®æ ‡å˜é‡ '{main_target}' ä¸åœ¨æ•°æ®é›†ä¸­ï¼Œè¯·æ£€æŸ¥åˆ—åã€‚")
print(f"å½“å‰é€‰æ‹©çš„ç›®æ ‡å˜é‡: {main_target}")


# ==================== æ–°å¢EDAæ¢ç´¢æ€§æ•°æ®åˆ†æéƒ¨åˆ† ====================
print("\n" + "=" * 80)
print("EDA æ¢ç´¢æ€§æ•°æ®åˆ†æ")
print("=" * 80)

# 2. æ•°æ®æ¦‚è§ˆ
print("\n2. æ•°æ®åŸºæœ¬ä¿¡æ¯")
print("-" * 50)

print("æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
print(f"æ ·æœ¬æ•°é‡: {len(data)}")

# æ•°æ®ç±»å‹å’Œç¼ºå¤±å€¼ä¿¡æ¯
print("\næ•°æ®ç±»å‹å’Œç¼ºå¤±å€¼:")
info_df = pd.DataFrame({
    'æ•°æ®ç±»å‹': data[feature_cols + [main_target]].dtypes,
    'ç¼ºå¤±å€¼æ•°é‡': data[feature_cols + [main_target]].isnull().sum(),
    'ç¼ºå¤±å€¼æ¯”ä¾‹(%)': (data[feature_cols + [main_target]].isnull().sum() / len(data) * 100).round(2),
    'å”¯ä¸€å€¼æ•°é‡': data[feature_cols + [main_target]].nunique()
})
print(info_df)

# åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
print("\nç‰¹å¾å˜é‡æè¿°æ€§ç»Ÿè®¡:")
desc_stats = data[feature_cols].describe()
print(desc_stats.round(4))

# 3. ç›®æ ‡å˜é‡åˆ†æ
print("\n3. ç›®æ ‡å˜é‡åˆ†æ")
print("-" * 50)

# ç›®æ ‡å˜é‡åˆ†å¸ƒ
target_counts = data[main_target].value_counts()
target_props = data[main_target].value_counts(normalize=True)

print("ç›®æ ‡å˜é‡åˆ†å¸ƒ:")
target_summary = pd.DataFrame({
    'æ•°é‡': target_counts,
    'æ¯”ä¾‹(%)': (target_props * 100).round(2)
})
print(target_summary)

# ç›®æ ‡å˜é‡å¯è§†åŒ–
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# æŸ±çŠ¶å›¾
axes[0].bar(target_counts.index, target_counts.values)
axes[0].set_title(f'{main_target} åˆ†å¸ƒ')
axes[0].set_xlabel('ç±»åˆ«')
axes[0].set_ylabel('æ ·æœ¬æ•°é‡')
for i, v in enumerate(target_counts.values):
    axes[0].text(i, v + 0.5, str(v), ha='center', va='bottom')

# é¥¼å›¾
axes[1].pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%', startangle=90)
axes[1].set_title(f'{main_target} æ¯”ä¾‹åˆ†å¸ƒ')

# å¦‚æœæœ‰å¤šä¸ªç›®æ ‡å˜é‡ï¼Œæ˜¾ç¤ºç›¸å…³æ€§
if len(target_cols) > 1:
    target_corr = data[target_cols].corr()
    sns.heatmap(target_corr, annot=True, cmap='coolwarm', center=0, ax=axes[2])
    axes[2].set_title('ç›®æ ‡å˜é‡é—´ç›¸å…³æ€§')
else:
    axes[2].text(0.5, 0.5, 'åªæœ‰ä¸€ä¸ªç›®æ ‡å˜é‡', ha='center', va='center', transform=axes[2].transAxes)
    axes[2].set_title('ç›®æ ‡å˜é‡ç›¸å…³æ€§åˆ†æ')

plt.tight_layout()
plt.savefig('target_variable_analysis.png', dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
target_summary.to_csv('target_variable_summary.csv', encoding='utf-8-sig')


# 4. ç‰¹å¾å˜é‡åˆ†å¸ƒåˆ†æ
print("\n4. ç‰¹å¾å˜é‡åˆ†å¸ƒåˆ†æ")
print("-" * 50)

# è®¡ç®—éœ€è¦çš„å­å›¾æ•°é‡
n_features = len(feature_cols)
n_cols = 4
n_rows = (n_features + n_cols - 1) // n_cols

# ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾
print("ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾...")
fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))
axes = axes.ravel() if n_rows > 1 else [axes] if n_cols == 1 else axes

for i, col in enumerate(feature_cols):
    if i < len(axes):
        # ç›´æ–¹å›¾å’ŒKDE
        axes[i].hist(data[col].dropna(), bins=30, density=True, alpha=0.7, edgecolor='black')

        # æ·»åŠ KDEæ›²çº¿
        try:
            data[col].dropna().plot.density(ax=axes[i], color='red', linewidth=2)
        except:
            pass

        axes[i].set_title(f'{col} åˆ†å¸ƒ')
        axes[i].set_xlabel(col)
        axes[i].set_ylabel('å¯†åº¦')
        axes[i].grid(True, alpha=0.3)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_val = data[col].mean()
        median_val = data[col].median()
        axes[i].axvline(mean_val, color='green', linestyle='--', alpha=0.7, label=f'å‡å€¼: {mean_val:.2f}')
        axes[i].axvline(median_val, color='orange', linestyle='--', alpha=0.7, label=f'ä¸­ä½æ•°: {median_val:.2f}')
        axes[i].legend(fontsize=8)

# éšè—å¤šä½™çš„å­å›¾
for j in range(i + 1, len(axes)):
    axes[j].set_visible(False)

plt.tight_layout()
plt.savefig('feature_distribution_analysis.png', dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
desc_stats.to_csv('feature_descriptive_statistics.csv', encoding='utf-8-sig')

# 5. ç®±çº¿å›¾åˆ†æ
print("\n5. ç®±çº¿å›¾åˆ†æï¼ˆå¼‚å¸¸å€¼æ£€æµ‹ï¼‰")
print("-" * 50)

print("ç»˜åˆ¶ç®±çº¿å›¾åˆ†æå¼‚å¸¸å€¼...")
fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))
axes = axes.ravel() if n_rows > 1 else [axes] if n_cols == 1 else axes

outlier_summary = {}

for i, col in enumerate(feature_cols):
    if i < len(axes):
        # ç®±çº¿å›¾
        box_plot = axes[i].boxplot(data[col].dropna(), patch_artist=True)
        box_plot['boxes'][0].set_facecolor('lightblue')

        axes[i].set_title(f'{col} ç®±çº¿å›¾')
        axes[i].set_ylabel(col)
        axes[i].grid(True, alpha=0.3)

        # è®¡ç®—å¼‚å¸¸å€¼
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)][col]
        outlier_count = len(outliers)
        outlier_percent = (outlier_count / len(data)) * 100

        outlier_summary[col] = {
            'count': outlier_count,
            'percentage': outlier_percent,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound
        }

        # æ·»åŠ å¼‚å¸¸å€¼ä¿¡æ¯
        axes[i].text(0.02, 0.98, f'å¼‚å¸¸å€¼: {outlier_count} ({outlier_percent:.1f}%)',
                     transform=axes[i].transAxes, verticalalignment='top',
                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# éšè—å¤šä½™çš„å­å›¾
for j in range(i + 1, len(axes)):
    axes[j].set_visible(False)

plt.tight_layout()
plt.savefig('boxplot_outlier_analysis.png', dpi=300)
plt.show()

# å¼‚å¸¸å€¼ç»Ÿè®¡
print("\nå¼‚å¸¸å€¼ç»Ÿè®¡æ€»ç»“:")
outlier_df = pd.DataFrame(outlier_summary).T
outlier_df.columns = ['å¼‚å¸¸å€¼æ•°é‡', 'å¼‚å¸¸å€¼æ¯”ä¾‹(%)', 'ä¸‹ç•Œ', 'ä¸Šç•Œ']
outlier_df['å¼‚å¸¸å€¼æ¯”ä¾‹(%)'] = outlier_df['å¼‚å¸¸å€¼æ¯”ä¾‹(%)'].round(2)
print(outlier_df)

# 6. ç‰¹å¾ç›¸å…³æ€§åˆ†æ
print("\n6. ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
print("-" * 50)

print("è®¡ç®—ç‰¹å¾é—´ç›¸å…³æ€§...")
correlation_matrix = data[feature_cols].corr()

# ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": 0.5}, fmt='.3f')
plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
plt.tight_layout()
plt.savefig('feature_correlation_matrix.png', dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
correlation_matrix.to_csv('feature_correlation_matrix.csv', encoding='utf-8-sig')


# é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ï¼Œ
print("\né«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > 0.9):")
high_corr_pairs = []
for i in range(len(correlation_matrix.columns)):
    for j in range(i + 1, len(correlation_matrix.columns)):
        corr_val = correlation_matrix.iloc[i, j]
        if abs(corr_val) > 0.9:
            high_corr_pairs.append({
                'feature1': correlation_matrix.columns[i],
                'feature2': correlation_matrix.columns[j],
                'correlation': corr_val
            })

if high_corr_pairs:
    high_corr_df = pd.DataFrame(high_corr_pairs)
    high_corr_df = high_corr_df.sort_values('correlation', key=abs, ascending=False)
    print(high_corr_df)
else:
    print("æ²¡æœ‰å‘ç°é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹")

#å¯¹é«˜ç›¸å…³ç‰¹å¾è¿›è¡Œå¤„ç†
if high_corr_pairs:
    to_remove = set()
    for pair in high_corr_pairs:
        # ç®€å•ç­–ç•¥ï¼šç§»é™¤ç›¸å…³æ€§è¾ƒé«˜å¯¹ä¸­çš„ç¬¬äºŒä¸ªç‰¹å¾
        to_remove.add(pair['feature2'])
    print(f"\nå»ºè®®ç§»é™¤ä»¥ä¸‹é«˜ç›¸å…³æ€§ç‰¹å¾ä»¥å‡å°‘å¤šé‡å…±çº¿æ€§: {to_remove}")
    feature_cols = [col for col in feature_cols if col not in to_remove]
    print(f"æ›´æ–°åçš„ç‰¹å¾åˆ—è¡¨: {feature_cols}")
else:
    print("æ— éœ€ç§»é™¤ä»»ä½•ç‰¹å¾")

# 7. ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³ç³»åˆ†æ
print("\n7. ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³ç³»åˆ†æ")
print("-" * 50)

# ä¸åŒç±»åˆ«ä¸‹çš„ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”
unique_targets = data[main_target].unique()
n_targets = len(unique_targets)

print(f"ç»˜åˆ¶ä¸åŒ{main_target}ç±»åˆ«ä¸‹çš„ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”...")

# ä¸ºæ¯ä¸ªç‰¹å¾åˆ›å»ºåˆ†ç±»å¯¹æ¯”å›¾
for idx, col in enumerate(feature_cols[:6]):  # åªæ˜¾ç¤ºå‰6ä¸ªç‰¹å¾é¿å…å›¾å¤ªå¤š
    plt.figure(figsize=(15, 5))

    # å°æç´å›¾
    plt.subplot(1, 3, 1)
    sns.violinplot(data=data, x=main_target, y=col)
    plt.title(f'{col} - å°æç´å›¾')
    plt.xticks(rotation=45)

    # ç®±çº¿å›¾
    plt.subplot(1, 3, 2)
    sns.boxplot(data=data, x=main_target, y=col)
    plt.title(f'{col} - ç®±çº¿å›¾å¯¹æ¯”')
    plt.xticks(rotation=45)

    # ç›´æ–¹å›¾å åŠ 
    plt.subplot(1, 3, 3)
    for target in unique_targets:
        subset = data[data[main_target] == target][col].dropna()
        plt.hist(subset, alpha=0.6, label=f'{target} (n={len(subset)})', bins=20)
    plt.xlabel(col)
    plt.ylabel('é¢‘æ¬¡')
    plt.title(f'{col} - åˆ†å¸ƒå¯¹æ¯”')
    plt.legend()

    plt.tight_layout()
    plt.savefig(f'feature_{col}_by_{main_target}.png', dpi=300)
    plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
# è®¡ç®—å„ç±»åˆ«ä¸‹çš„å‡å€¼å’Œæ ‡å‡†å·®
feature_target_summary = {}
for col in feature_cols:
    stats = []
    for target in unique_targets:
        subset = data[data[main_target] == target][col]
        stats.append({
            'ç±»åˆ«': target,
            'å‡å€¼': subset.mean(),
            'æ ‡å‡†å·®': subset.std(),
            'æ ·æœ¬æ•°': len(subset)
        })
    feature_target_summary[col] = pd.DataFrame(stats)
    feature_target_summary[col].to_csv(f'feature_{col}_by_{main_target}_summary.csv', encoding='utf-8-sig', index=False)
    print(f"å·²ä¿å­˜ {col} æŒ‰ {main_target} åˆ†ç±»çš„ç»Ÿè®¡ä¿¡æ¯åˆ° CSV æ–‡ä»¶")

# 8. ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§
print("\n8. ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§")
print("-" * 50)

# å¦‚æœç›®æ ‡å˜é‡æ˜¯æ•°å€¼å‹ï¼Œè®¡ç®—ç›¸å…³æ€§
if data[main_target].dtype in ['int64', 'float64']:
    target_correlation = data[feature_cols + [main_target]].corr()[main_target].drop(main_target).sort_values(key=abs,
                                                                                                              ascending=False)

    print("ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§:")
    print(target_correlation)

    # å¯è§†åŒ–ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§
    plt.figure(figsize=(10, 8))
    target_correlation.plot(kind='barh')
    plt.title(f'ç‰¹å¾ä¸{main_target}çš„ç›¸å…³æ€§')
    plt.xlabel('ç›¸å…³ç³»æ•°')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(f'feature_target_correlation_{main_target}.png', dpi=300)
    plt.show()
    # ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
    target_correlation.to_csv(f'feature_target_correlation_{main_target}.csv', encoding='utf-8-sig')


else:
    # å¦‚æœæ˜¯åˆ†ç±»å˜é‡ï¼Œä½¿ç”¨æ–¹å·®åˆ†æ
    from scipy import stats

    print("ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³è”æ€§åˆ†æ (F-ç»Ÿè®¡é‡):")
    f_stats = []
    p_values = []

    for col in feature_cols:
        groups = [data[data[main_target] == target][col].dropna() for target in unique_targets]
        f_stat, p_val = stats.f_oneway(*groups)
        f_stats.append(f_stat)
        p_values.append(p_val)

    anova_results = pd.DataFrame({
        'Feature': feature_cols,
        'F_statistic': f_stats,
        'p_value': p_values,
        'significant': ['æ˜¯' if p < 0.05 else 'å¦' for p in p_values]
    }).sort_values('F_statistic', ascending=False)

    print(anova_results)

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.preprocessing import StandardScaler
import warnings

print("=== å¢å¼ºç‰ˆç‰¹å¾å…³ç³»åˆ†æ ===")
# ç¡®ä¿æ•°æ®å‡†å¤‡
if 'data' not in locals():
    print("è¯·å…ˆå‡†å¤‡æ•°æ®å˜é‡")
else:
    # æ•°æ®åŸºæœ¬ä¿¡æ¯
    print(f"æ•°æ®é›†å½¢çŠ¶: {data.shape}")
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"ç›®æ ‡å˜é‡: {main_target}")
    print(f"ç±»åˆ«åˆ†å¸ƒ:\n{data[main_target].value_counts()}")

# åˆ›å»ºç±»åˆ«åç§°æ˜ å°„
if 'class_names' in locals():
    class_mapping = {i: class_names[i] for i in range(len(class_names))}
    data_plot = data.copy()
    data_plot[main_target + '_name'] = data_plot[main_target].map(class_mapping)
    hue_col = main_target + '_name'
else:
    hue_col = main_target
    data_plot = data.copy()


# 2. å¢å¼ºç‰ˆ Pairplot
def enhanced_pairplot(data, feature_cols, hue_col, main_target):
    """åˆ›å»ºå¢å¼ºç‰ˆçš„ç‰¹å¾å…³ç³»å›¾"""

    # è®¡ç®—éœ€è¦çš„å­å›¾æ•°é‡
    n_features = len(feature_cols)

    # åˆ›å»ºè‡ªå®šä¹‰çš„pairplot
    fig, axes = plt.subplots(n_features, n_features, figsize=(4 * n_features, 4 * n_features))

    # è·å–ç±»åˆ«ä¿¡æ¯
    unique_classes = data[main_target].unique()
    colors = sns.color_palette("husl", len(unique_classes))
    class_colors = {cls: colors[i] for i, cls in enumerate(unique_classes)}

    for i in range(n_features):
        for j in range(n_features):
            ax = axes[i, j]

            if i == j:
                # å¯¹è§’çº¿ï¼šåˆ†å¸ƒå›¾
                for cls in unique_classes:
                    class_data = data[data[main_target] == cls][feature_cols[i]]

                    # ç»˜åˆ¶ç›´æ–¹å›¾å’Œæ ¸å¯†åº¦ä¼°è®¡
                    ax.hist(class_data, bins=20, alpha=0.6,
                            label=f'{hue_col}: {cls}' if hue_col == main_target else f'{class_names[cls] if "class_names" in locals() else cls}',
                            color=class_colors[cls], density=True)

                    # æ·»åŠ æ ¸å¯†åº¦ä¼°è®¡æ›²çº¿
                    if len(class_data) > 1:
                        kde_x = np.linspace(class_data.min(), class_data.max(), 100)
                        kde = stats.gaussian_kde(class_data)
                        ax.plot(kde_x, kde(kde_x), color=class_colors[cls], linewidth=2, alpha=0.8)

                ax.set_xlabel(feature_cols[i])
                ax.set_ylabel('å¯†åº¦')
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)

                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                overall_mean = data[feature_cols[i]].mean()
                overall_std = data[feature_cols[i]].std()
                ax.axvline(overall_mean, color='red', linestyle='--', alpha=0.7, linewidth=1)
                ax.text(0.02, 0.98, f'Î¼={overall_mean:.2f}\nÏƒ={overall_std:.2f}',
                        transform=ax.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

            else:
                # éå¯¹è§’çº¿ï¼šæ•£ç‚¹å›¾
                for cls in unique_classes:
                    class_data = data[data[main_target] == cls]
                    x_data = class_data[feature_cols[j]]
                    y_data = class_data[feature_cols[i]]

                    # æ•£ç‚¹å›¾
                    ax.scatter(x_data, y_data, alpha=0.6, s=20,
                               color=class_colors[cls],
                               label=f'{class_names[cls] if "class_names" in locals() else cls}')

                    # æ·»åŠ å›å½’çº¿
                    if len(x_data) > 1 and len(y_data) > 1:
                        try:
                            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)
                            line_x = np.array([x_data.min(), x_data.max()])
                            line_y = slope * line_x + intercept
                            ax.plot(line_x, line_y, color=class_colors[cls],
                                    linestyle='-', alpha=0.8, linewidth=1.5)
                        except:
                            pass

                ax.set_xlabel(feature_cols[j])
                ax.set_ylabel(feature_cols[i])
                ax.grid(True, alpha=0.3)

                # è®¡ç®—æ€»ä½“ç›¸å…³æ€§
                corr_coef = data[feature_cols[j]].corr(data[feature_cols[i]])
                ax.text(0.02, 0.98, f'r={corr_coef:.3f}',
                        transform=ax.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))

                # åªåœ¨ç¬¬ä¸€è¡Œæ˜¾ç¤ºå›¾ä¾‹
                if i == 0 and j == 1:
                    ax.legend(loc='upper right', fontsize=8)

    plt.tight_layout()
    return fig


# 3. ç»˜åˆ¶å¢å¼ºç‰ˆpairplot
print("ç»˜åˆ¶å¢å¼ºç‰ˆç‰¹å¾å…³ç³»å›¾...")
enhanced_fig = enhanced_pairplot(data_plot, feature_cols, hue_col, main_target)
enhanced_fig.suptitle('å¢å¼ºç‰ˆç‰¹å¾ä¸¤ä¸¤å…³ç³»åˆ†æ\n(åŒ…å«åˆ†å¸ƒã€ç›¸å…³æ€§å’Œå›å½’çº¿)',
                      fontsize=16, fontweight='bold', y=0.995)
enhanced_fig.savefig('enhanced_pairplot_features.png', dpi=300, bbox_inches='tight')
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
# è®¡ç®—å¹¶ä¿å­˜ç›¸å…³æ€§çŸ©é˜µ
corr_matrix = data[feature_cols].corr()
corr_matrix.to_csv('enhanced_pairplot_correlation_matrix.csv', encoding='utf-8-sig')
# è®¡ç®—å¹¶ä¿å­˜å„ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡
desc_stats = data[feature_cols].describe().round(4)
desc_stats.to_csv('enhanced_pairplot_descriptive_statistics.csv', encoding='utf-8-sig')



# 4. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾åˆ†æ
print("ç»˜åˆ¶ç‰¹å¾ç›¸å…³æ€§åˆ†æ...")
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))

# 4.1 æ€»ä½“ç›¸å…³æ€§çŸ©é˜µ
corr_matrix = data[feature_cols].corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

im1 = sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                  square=True, linewidths=0.5, cbar_kws={"shrink": .5}, ax=ax1)
ax1.set_title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ (æ€»ä½“)', fontsize=14, fontweight='bold')

# 4.2 æŒ‰ç±»åˆ«çš„ç›¸å…³æ€§å·®å¼‚
unique_classes = data[main_target].unique()
if len(unique_classes) >= 2:
    class_corr_diff = {}
    for i, cls in enumerate(unique_classes[:2]):  # æ¯”è¾ƒå‰ä¸¤ä¸ªç±»åˆ«
        class_data = data[data[main_target] == cls][feature_cols]
        class_corr_diff[cls] = class_data.corr()

    # è®¡ç®—ç›¸å…³æ€§å·®å¼‚
    corr_diff = class_corr_diff[unique_classes[0]] - class_corr_diff[unique_classes[1]]

    im2 = sns.heatmap(corr_diff, annot=True, cmap='RdBu_r', center=0,
                      square=True, linewidths=0.5, cbar_kws={"shrink": .5}, ax=ax2)
    class_0_name = class_names[unique_classes[0]] if 'class_names' in locals() else unique_classes[0]
    class_1_name = class_names[unique_classes[1]] if 'class_names' in locals() else unique_classes[1]
    ax2.set_title(f'ç±»åˆ«é—´ç›¸å…³æ€§å·®å¼‚\n({class_0_name} - {class_1_name})', fontsize=14, fontweight='bold')

# 4.3 ç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„å…³ç³»å¼ºåº¦
target_corr = {}
for feature in feature_cols:
    correlations = []
    for cls in unique_classes:
        class_data = data[data[main_target] == cls][feature]
        # è®¡ç®—ä¸ç±»åˆ«ç¼–ç çš„ç›¸å…³æ€§
        class_encoded = (data[main_target] == cls).astype(int)
        corr = data[feature].corr(class_encoded)
        correlations.append(abs(corr))  # ä½¿ç”¨ç»å¯¹å€¼
    target_corr[feature] = max(correlations)  # å–æœ€å¤§ç›¸å…³æ€§

target_corr_df = pd.DataFrame(list(target_corr.items()), columns=['Feature', 'Target_Correlation'])
target_corr_df = target_corr_df.sort_values('Target_Correlation', ascending=True)

bars = ax3.barh(target_corr_df['Feature'], target_corr_df['Target_Correlation'],
                color='steelblue', alpha=0.7)
ax3.set_xlabel('ä¸ç›®æ ‡å˜é‡çš„æœ€å¤§ç›¸å…³æ€§')
ax3.set_title('ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³ç³»å¼ºåº¦', fontsize=14, fontweight='bold')
ax3.grid(axis='x', alpha=0.3)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, corr in zip(bars, target_corr_df['Target_Correlation']):
    ax3.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2,
             f'{corr:.3f}', ha='left', va='center', fontsize=10)

# 4.4 ç‰¹å¾åˆ†ç¦»åº¦åˆ†æï¼ˆå„ç±»åˆ«é—´ç‰¹å¾å€¼çš„åˆ†ç¦»ç¨‹åº¦ï¼‰
separation_scores = {}
for feature in feature_cols:
    class_means = []
    class_stds = []

    for cls in unique_classes:
        class_data = data[data[main_target] == cls][feature]
        class_means.append(class_data.mean())
        class_stds.append(class_data.std())

    # è®¡ç®—åˆ†ç¦»åº¦ï¼šç±»é—´æ–¹å·® / ç±»å†…æ–¹å·®çš„å¹³å‡
    between_var = np.var(class_means)
    within_var = np.mean([std ** 2 for std in class_stds])
    separation = between_var / (within_var + 1e-6)  # é¿å…é™¤é›¶
    separation_scores[feature] = separation

sep_df = pd.DataFrame(list(separation_scores.items()), columns=['Feature', 'Separation_Score'])
sep_df = sep_df.sort_values('Separation_Score', ascending=True)

bars2 = ax4.barh(sep_df['Feature'], sep_df['Separation_Score'],
                 color='coral', alpha=0.7)
ax4.set_xlabel('åˆ†ç¦»åº¦å¾—åˆ† (ç±»é—´æ–¹å·®/ç±»å†…æ–¹å·®)')
ax4.set_title('ç‰¹å¾ç±»åˆ«åˆ†ç¦»åº¦åˆ†æ', fontsize=14, fontweight='bold')
ax4.grid(axis='x', alpha=0.3)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, score in zip(bars2, sep_df['Separation_Score']):
    ax4.text(bar.get_width() + max(sep_df['Separation_Score']) * 0.01,
             bar.get_y() + bar.get_height() / 2,
             f'{score:.2f}', ha='left', va='center', fontsize=10)

plt.tight_layout()
plt.savefig('feature_correlation_analysis.png', dpi=300, bbox_inches='tight')
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
corr_matrix.to_csv('feature_correlation_matrix_overall.csv', encoding='utf-8-sig')
target_corr_df.to_csv('feature_target_correlation_strength.csv', encoding='utf-8-sig', index=False)

# 5. åˆ†ç±»åˆ«çš„ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”
print("ç»˜åˆ¶åˆ†ç±»åˆ«ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”...")
n_cols = 3
n_rows = (len(feature_cols) + n_cols - 1) // n_cols
fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))
axes = axes.ravel() if len(feature_cols) > 1 else [axes]

for idx, feature in enumerate(feature_cols):
    ax = axes[idx]

    # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶ç®±çº¿å›¾å’Œå°æç´å›¾çš„ç»„åˆ
    class_data = []
    class_labels = []

    for cls in unique_classes:
        class_feature_data = data[data[main_target] == cls][feature]
        class_data.append(class_feature_data)
        class_labels.append(class_names[cls] if 'class_names' in locals() else f'Class {cls}')

    # ç»˜åˆ¶å°æç´å›¾
    parts = ax.violinplot(class_data, positions=range(len(unique_classes)),
                          showmeans=True, showmedians=True)

    # è‡ªå®šä¹‰é¢œè‰²
    colors = sns.color_palette("husl", len(unique_classes))
    for pc, color in zip(parts['bodies'], colors):
        pc.set_facecolor(color)
        pc.set_alpha(0.7)

    # è®¾ç½®æ ·å¼
    ax.set_xticks(range(len(unique_classes)))
    ax.set_xticklabels(class_labels, rotation=45, ha='right')
    ax.set_ylabel(feature)
    ax.set_title(f'{feature} åˆ†å¸ƒå¯¹æ¯”')
    ax.grid(True, alpha=0.3)

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    stats_text = ""
    for i, (cls, class_feature_data) in enumerate(zip(unique_classes, class_data)):
        mean_val = np.mean(class_feature_data)
        std_val = np.std(class_feature_data)
        median_val = np.median(class_feature_data)
        stats_text += f"{class_labels[i]}: Î¼={mean_val:.2f}, Ïƒ={std_val:.2f}, Med={median_val:.2f}\n"

    ax.text(0.02, 0.98, stats_text.strip(), transform=ax.transAxes,
            verticalalignment='top', fontsize=8,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

    # è¿›è¡Œç»Ÿè®¡æ£€éªŒï¼ˆANOVAï¼‰
    if len(class_data) > 1 and all(len(cd) > 1 for cd in class_data):
        try:
            f_stat, p_value = stats.f_oneway(*class_data)
            significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
            ax.text(0.98, 0.98, f'ANOVA: p={p_value:.3f} {significance}',
                    transform=ax.transAxes, verticalalignment='top', horizontalalignment='right',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
        except:
            pass

# éšè—å¤šä½™çš„å­å›¾
for idx in range(len(feature_cols), len(axes)):
    axes[idx].set_visible(False)

plt.tight_layout()
plt.savefig('feature_distribution_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
for feature in feature_cols:
    stats = []
    for cls in unique_classes:
        class_feature_data = data[data[main_target] == cls][feature]
        stats.append({
            'ç±»åˆ«': class_names[cls] if 'class_names' in locals() else f'Class {cls}',
            'å‡å€¼': class_feature_data.mean(),
            'æ ‡å‡†å·®': class_feature_data.std(),
            'ä¸­ä½æ•°': class_feature_data.median(),
            'æ ·æœ¬æ•°': len(class_feature_data)
        })
    stats_df = pd.DataFrame(stats)
    stats_df.to_csv(f'feature_{feature}_distribution_comparison.csv', encoding='utf-8-sig', index=False)
    print(f"å·²ä¿å­˜ {feature} æŒ‰ {main_target} åˆ†ç±»çš„ç»Ÿè®¡ä¿¡æ¯åˆ° CSV æ–‡ä»¶")
# è®¡ç®—å¹¶ä¿å­˜ANOVAç»“æœ
anova_results = []
for feature in feature_cols:
    class_data = [data[data[main_target] == cls][feature] for cls in unique_classes]
    if len(class_data) > 1 and all(len(cd) > 1 for cd in class_data):
        try:
            f_stat, p_value = stats.f_oneway(*class_data)
            anova_results.append({
                'Feature': feature,
                'F_statistic': f_stat,
                'p_value': p_value,
                'significant': 'æ˜¯' if p_value < 0.05 else 'å¦'
            })
        except:
            pass
anova_df = pd.DataFrame(anova_results)
anova_df.to_csv('feature_anova_results.csv', encoding='utf-8-sig', index=False)
print("å·²ä¿å­˜ ANOVA ç»“æœåˆ° CSV æ–‡ä»¶")


# 6. ç‰¹å¾é‡è¦æ€§å’Œå¯åˆ†ç¦»æ€§ç»¼åˆåˆ†æ
print("ç”Ÿæˆç‰¹å¾åˆ†æç»¼åˆæŠ¥å‘Š...")

# è®¡ç®—å„ç§ç‰¹å¾è¯„åˆ†
feature_analysis = pd.DataFrame({
    'Feature': feature_cols,
    'Target_Correlation': [target_corr[f] for f in feature_cols],
    'Separation_Score': [separation_scores[f] for f in feature_cols],
    'Variance': [data[f].var() for f in feature_cols],
    'CV': [data[f].std() / abs(data[f].mean()) if abs(data[f].mean()) > 1e-6 else 0 for f in feature_cols]
})

# æ ‡å‡†åŒ–è¯„åˆ†
scaler = StandardScaler()
feature_analysis['Target_Correlation_Norm'] = scaler.fit_transform(feature_analysis[['Target_Correlation']])
feature_analysis['Separation_Score_Norm'] = scaler.fit_transform(feature_analysis[['Separation_Score']])
feature_analysis['Variance_Norm'] = scaler.fit_transform(feature_analysis[['Variance']])

# è®¡ç®—ç»¼åˆè¯„åˆ†
feature_analysis['Composite_Score'] = (
        0.4 * feature_analysis['Target_Correlation_Norm'] +
        0.4 * feature_analysis['Separation_Score_Norm'] +
        0.2 * feature_analysis['Variance_Norm']
)

feature_analysis = feature_analysis.sort_values('Composite_Score', ascending=False)

# å¯è§†åŒ–ç»¼åˆåˆ†æ
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

# ç»¼åˆè¯„åˆ†æ’åº
bars1 = ax1.barh(feature_analysis['Feature'], feature_analysis['Composite_Score'],
                 color='steelblue', alpha=0.7)
ax1.set_xlabel('ç»¼åˆè¯„åˆ† (æ ‡å‡†åŒ–)')
ax1.set_title('ç‰¹å¾ç»¼åˆé‡è¦æ€§æ’åº', fontsize=14, fontweight='bold')
ax1.grid(axis='x', alpha=0.3)

# æ•£ç‚¹å›¾ï¼šç›¸å…³æ€§ vs åˆ†ç¦»åº¦
scatter = ax2.scatter(feature_analysis['Target_Correlation'],
                      feature_analysis['Separation_Score'],
                      s=feature_analysis['Variance'] * 10,  # ç”¨æ–¹å·®æ§åˆ¶ç‚¹å¤§å°
                      alpha=0.7, c=range(len(feature_analysis)), cmap='viridis')

for i, feature in enumerate(feature_analysis['Feature']):
    ax2.annotate(feature,
                 (feature_analysis.iloc[i]['Target_Correlation'],
                  feature_analysis.iloc[i]['Separation_Score']),
                 xytext=(5, 5), textcoords='offset points', fontsize=9)

ax2.set_xlabel('ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§')
ax2.set_ylabel('ç±»åˆ«åˆ†ç¦»åº¦')
ax2.set_title('ç‰¹å¾æ€§èƒ½äºŒç»´åˆ†æ\n(æ°”æ³¡å¤§å°=æ–¹å·®)')
ax2.grid(True, alpha=0.3)

# å˜å¼‚ç³»æ•°åˆ†æ
bars3 = ax3.bar(feature_analysis['Feature'], feature_analysis['CV'],
                color='coral', alpha=0.7)
ax3.set_ylabel('å˜å¼‚ç³»æ•° (CV)')
ax3.set_title('ç‰¹å¾å˜å¼‚æ€§åˆ†æ', fontsize=14, fontweight='bold')
ax3.tick_params(axis='x', rotation=45)
ax3.grid(axis='y', alpha=0.3)

# é›·è¾¾å›¾ - å‰5ä¸ªé‡è¦ç‰¹å¾
top_5_features = feature_analysis.head(5)
categories = ['ç›®æ ‡ç›¸å…³æ€§', 'åˆ†ç¦»åº¦', 'æ–¹å·®', 'å˜å¼‚ç³»æ•°']

# æ•°æ®æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
radar_data = []
for _, row in top_5_features.iterrows():
    radar_values = [
        row['Target_Correlation'],
        row['Separation_Score'] / feature_analysis['Separation_Score'].max(),
        row['Variance'] / feature_analysis['Variance'].max(),
        min(row['CV'], 1.0)  # CVé™åˆ¶åœ¨1ä»¥å†…
    ]
    radar_data.append(radar_values)

# ç®€åŒ–çš„é›·è¾¾å›¾æ›¿ä»£æ–¹æ¡ˆï¼šå †å æ¡å½¢å›¾
bottom = np.zeros(len(top_5_features))
colors_radar = ['red', 'blue', 'green', 'orange']

for i, category in enumerate(categories):
    values = [rd[i] for rd in radar_data]
    ax4.bar(top_5_features['Feature'], values, bottom=bottom,
            label=category, color=colors_radar[i], alpha=0.7)
    bottom += values

ax4.set_ylabel('æ ‡å‡†åŒ–å¾—åˆ† (ç´¯ç§¯)')
ax4.set_title('Top 5 ç‰¹å¾å¤šç»´åº¦åˆ†æ', fontsize=14, fontweight='bold')
ax4.legend(loc='upper left')
ax4.tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.savefig('comprehensive_feature_analysis.png', dpi=300, bbox_inches='tight')
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
feature_analysis.to_csv('comprehensive_feature_analysis.csv', encoding='utf-8-sig', index=False)


# 7. ç”Ÿæˆè¯¦ç»†çš„æ–‡å­—æŠ¥å‘Š
print("\n" + "=" * 80)
print("ç‰¹å¾å…³ç³»åˆ†æç»¼åˆæŠ¥å‘Š")
print("=" * 80)

print(f"\nğŸ“Š æ•°æ®é›†æ¦‚å†µ:")
print(f"   - æ ·æœ¬æ•°é‡: {data.shape[0]}")
print(f"   - ç‰¹å¾æ•°é‡: {len(feature_cols)}")
print(f"   - ç›®æ ‡å˜é‡ç±»åˆ«æ•°: {len(unique_classes)}")

print(f"\nğŸ† ç‰¹å¾é‡è¦æ€§æ’åº (Top 5):")
for i, (_, row) in enumerate(feature_analysis.head(5).iterrows(), 1):
    print(f"   {i}. {row['Feature']}")
    print(f"      - ç›®æ ‡ç›¸å…³æ€§: {row['Target_Correlation']:.3f}")
    print(f"      - åˆ†ç¦»åº¦å¾—åˆ†: {row['Separation_Score']:.3f}")
    print(f"      - æ–¹å·®: {row['Variance']:.3f}")
    print(f"      - ç»¼åˆè¯„åˆ†: {row['Composite_Score']:.3f}")

print(f"\nğŸ“ˆ ç±»åˆ«åˆ†ç¦»æ€§åˆ†æ:")
for cls in unique_classes:
    cls_name = class_names[cls] if 'class_names' in locals() else f'ç±»åˆ« {cls}'
    cls_count = sum(data[main_target] == cls)
    cls_percent = cls_count / len(data) * 100
    print(f"   - {cls_name}: {cls_count} æ ·æœ¬ ({cls_percent:.1f}%)")

best_separating_feature = feature_analysis.loc[feature_analysis['Separation_Score'].idxmax(), 'Feature']
print(f"   - æœ€ä½³åˆ†ç¦»ç‰¹å¾: {best_separating_feature}")
print(f"   - åˆ†ç¦»åº¦å¾—åˆ†: {feature_analysis['Separation_Score'].max():.3f}")

print(f"\nâš ï¸  æ•°æ®è´¨é‡æé†’:")
low_var_features = feature_analysis[feature_analysis['Variance'] < feature_analysis['Variance'].quantile(0.25)][
    'Feature'].tolist()
if low_var_features:
    print(f"   - ä½æ–¹å·®ç‰¹å¾ (å¯èƒ½ä¿¡æ¯é‡ä¸è¶³): {low_var_features}")

high_cv_features = feature_analysis[feature_analysis['CV'] > 1.0]['Feature'].tolist()
if high_cv_features:
    print(f"   - é«˜å˜å¼‚ç‰¹å¾ (å¯èƒ½éœ€è¦æ ‡å‡†åŒ–): {high_cv_features}")

print("\n" + "=" * 80)
print("åˆ†æå®Œæˆï¼æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜ä¸º PNG æ–‡ä»¶ã€‚")
print("=" * 80)

# 9. æ•°æ®è´¨é‡æŠ¥å‘Š
print("\n9. æ•°æ®è´¨é‡æŠ¥å‘Š")
print("-" * 50)

quality_report = {}

# ç¼ºå¤±å€¼åˆ†æ
missing_analysis = data[feature_cols].isnull().sum()
quality_report['missing_values'] = {
    'total_missing': missing_analysis.sum(),
    'features_with_missing': (missing_analysis > 0).sum(),
    'max_missing_percent': (missing_analysis.max() / len(data) * 100)
}

# å¼‚å¸¸å€¼åˆ†æ
total_outliers = sum([info['count'] for info in outlier_summary.values()])
quality_report['outliers'] = {
    'total_outliers': total_outliers,
    'outlier_percent': (total_outliers / (len(data) * len(feature_cols)) * 100),
    'features_with_outliers': sum([1 for info in outlier_summary.values() if info['count'] > 0])
}

# æ•°æ®ä¸å¹³è¡¡åˆ†æ
target_imbalance = target_props.max() / target_props.min()
quality_report['class_imbalance'] = {
    'imbalance_ratio': target_imbalance,
    'is_imbalanced': target_imbalance > 2
}

# ç‰¹å¾å¤šé‡å…±çº¿æ€§
high_corr_count = len(high_corr_pairs)
quality_report['multicollinearity'] = {
    'high_corr_pairs': high_corr_count,
    'potential_multicollinearity': high_corr_count > 0
}



print("æ•°æ®è´¨é‡æ€»ç»“:")
print(
    f"âœ“ æ•°æ®å®Œæ•´æ€§: {(1 - quality_report['missing_values']['total_missing'] / (len(data) * len(feature_cols))) * 100:.1f}%")
print(f"âœ“ å¼‚å¸¸å€¼æ¯”ä¾‹: {quality_report['outliers']['outlier_percent']:.2f}%")
print(f"âœ“ é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹: {quality_report['multicollinearity']['high_corr_pairs']} å¯¹")

# æ•°æ®è´¨é‡å¯è§†åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# ç¼ºå¤±å€¼å¯è§†åŒ–
axes[0, 0].bar(range(len(missing_analysis)), missing_analysis.values)
axes[0, 0].set_title('å„ç‰¹å¾ç¼ºå¤±å€¼æ•°é‡')
axes[0, 0].set_xticks(range(len(missing_analysis)))
axes[0, 0].set_xticklabels(missing_analysis.index, rotation=45)
axes[0, 0].set_ylabel('ç¼ºå¤±å€¼æ•°é‡')

# å¼‚å¸¸å€¼å¯è§†åŒ–
outlier_counts = [info['count'] for info in outlier_summary.values()]
axes[0, 1].bar(range(len(outlier_counts)), outlier_counts)
axes[0, 1].set_title('å„ç‰¹å¾å¼‚å¸¸å€¼æ•°é‡')
axes[0, 1].set_xticks(range(len(feature_cols)))
axes[0, 1].set_xticklabels(feature_cols, rotation=45)
axes[0, 1].set_ylabel('å¼‚å¸¸å€¼æ•°é‡')

# ç›®æ ‡å˜é‡ä¸å¹³è¡¡
axes[1, 0].bar(target_counts.index, target_counts.values)
axes[1, 0].set_title('ç›®æ ‡å˜é‡ç±»åˆ«åˆ†å¸ƒ')
axes[1, 0].set_ylabel('æ ·æœ¬æ•°é‡')

# ç‰¹å¾æ ‡å‡†å·®
feature_std = data[feature_cols].std().sort_values(ascending=False)
axes[1, 1].bar(range(len(feature_std)), feature_std.values)
axes[1, 1].set_title('ç‰¹å¾æ ‡å‡†å·®')
axes[1, 1].set_xticks(range(len(feature_std)))
axes[1, 1].set_xticklabels(feature_std.index, rotation=45)
axes[1, 1].set_ylabel('æ ‡å‡†å·®')

plt.tight_layout()
plt.savefig('data_quality_report.png', dpi=300, bbox_inches='tight')
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
missing_analysis.to_csv('data_quality_missing_values.csv', encoding='utf-8-sig')
outlier_df = pd.DataFrame.from_dict(outlier_summary, orient='index')
outlier_df.to_csv('data_quality_outlier_summary.csv', encoding='utf-8-sig')
target_counts.to_csv('data_quality_target_distribution.csv', encoding='utf-8-sig')
feature_std.to_csv('data_quality_feature_std.csv', encoding='utf-8-sig')

print(f"\nğŸ” EDAåˆ†æå®Œæˆï¼å‘ç°äº†ä»¥ä¸‹å…³é”®ä¿¡æ¯:")
print(f"   - æ•°æ®é›†åŒ…å« {len(feature_cols)} ä¸ªç‰¹å¾, {len(data)} ä¸ªæ ·æœ¬")
print(f"   - ç¼ºå¤±å€¼: {quality_report['missing_values']['total_missing']} ä¸ª")
print(f"   - å¼‚å¸¸å€¼: {total_outliers} ä¸ª ({quality_report['outliers']['outlier_percent']:.2f}%)")
print(f"   - å¤šé‡å…±çº¿æ€§: {'å­˜åœ¨' if quality_report['multicollinearity']['potential_multicollinearity'] else 'æ— '}")

# ==================== é¢„å¤„ç†å’Œå»ºæ¨¡éƒ¨åˆ† ====================

# 2. æ•°æ®é¢„å¤„ç†
print("\n" + "=" * 80)
print("æ•°æ®é¢„å¤„ç†")
print("=" * 80)

# æå–ç‰¹å¾å’Œç›®æ ‡
X = data[feature_cols].copy()
y = data[main_target].copy()

# å¤„ç†ç¼ºå¤±å€¼
print("å¤„ç†ç¼ºå¤±å€¼...")
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='median')
X_filled = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

print(f"å¤„ç†å‰ç¼ºå¤±å€¼: {X.isnull().sum().sum()}")
print(f"å¤„ç†åç¼ºå¤±å€¼: {X_filled.isnull().sum().sum()}")

# 3. å¼‚å¸¸å€¼å¤„ç†
print("\n3. å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†")
print("-" * 50)


def detect_outliers_iqr(df, column):
    """ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = (df[column] < lower_bound) | (df[column] > upper_bound)
    return outliers, lower_bound, upper_bound


# æ£€æµ‹å¼‚å¸¸å€¼
outlier_info = {}
total_outliers = pd.Series([False] * len(X_filled))

for col in feature_cols:
    outliers, lower, upper = detect_outliers_iqr(X_filled, col)
    outlier_count = outliers.sum()
    outlier_percent = (outlier_count / len(X_filled)) * 100

    outlier_info[col] = {
        'count': outlier_count,
        'percentage': outlier_percent,
        'lower_bound': lower,
        'upper_bound': upper
    }

    total_outliers = total_outliers | outliers

print("å¼‚å¸¸å€¼ç»Ÿè®¡:")
for col, info in outlier_info.items():
    print(f"{col}: {info['count']} ({info['percentage']:.2f}%)")

print(f"\næ€»å¼‚å¸¸å€¼æ ·æœ¬æ•°: {total_outliers.sum()} ({(total_outliers.sum() / len(X_filled)) * 100:.2f}%)")

# å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥
outlier_threshold = 0.05  # 5%é˜ˆå€¼
if (total_outliers.sum() / len(X_filled)) > outlier_threshold:
    print("\nå¼‚å¸¸å€¼æ¯”ä¾‹è¾ƒé«˜ï¼Œä½¿ç”¨Winsorizingæ–¹æ³•å¤„ç†...")
    # Winsorizing: å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºåˆ†ä½æ•°å€¼
    X_clean = X_filled.copy()
    for col in feature_cols:
        outliers, lower, upper = detect_outliers_iqr(X_filled, col)
        X_clean.loc[X_clean[col] < lower, col] = lower
        X_clean.loc[X_clean[col] > upper, col] = upper
else:
    print("\nå¼‚å¸¸å€¼æ¯”ä¾‹è¾ƒä½ï¼Œç›´æ¥ç§»é™¤å¼‚å¸¸å€¼...")
    # ç§»é™¤å¼‚å¸¸å€¼
    X_clean = X_filled[~total_outliers].copy()
    y_clean = y[~total_outliers].copy()

print(f"å¤„ç†åæ•°æ®å½¢çŠ¶: {X_clean.shape}")

# 4. æ•°æ®æ ‡å‡†åŒ–
print("\n4. æ•°æ®æ ‡å‡†åŒ–")
print("-" * 50)

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X_clean), columns=X_clean.columns)

print("æ ‡å‡†åŒ–å‰åå¯¹æ¯”:")
comparison_df = pd.DataFrame({
    'åŸå§‹å‡å€¼': X_clean.mean(),
    'åŸå§‹æ ‡å‡†å·®': X_clean.std(),
    'æ ‡å‡†åŒ–åå‡å€¼': X_scaled.mean(),
    'æ ‡å‡†åŒ–åæ ‡å‡†å·®': X_scaled.std()
})
print(comparison_df.round(4))

# 5. PCAé™ç»´åˆ†æ
print("\n5. PCAé™ç»´åˆ†æ")
print("-" * 50)

# æ‰§è¡ŒPCAåˆ†æ
pca_full = PCA()
pca_result = pca_full.fit_transform(X_scaled)

# è®¡ç®—ç´¯ç§¯è§£é‡Šæ–¹å·®
explained_variance = pca_full.explained_variance_ratio_
cumulative_variance = np.cumsum(explained_variance)

# å¯è§†åŒ–PCAç»“æœ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# ä¸ªä½“è§£é‡Šæ–¹å·®
ax1.bar(range(1, len(explained_variance) + 1), explained_variance)
ax1.set_xlabel('ä¸»æˆåˆ†')
ax1.set_ylabel('è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax1.set_title('å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax1.grid(True, alpha=0.3)

# ç´¯ç§¯è§£é‡Šæ–¹å·®
ax2.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'bo-')
ax2.axhline(y=0.8, color='r', linestyle='--', label='80%')
ax2.axhline(y=0.9, color='g', linestyle='--', label='90%')
ax2.axhline(y=0.95, color='orange', linestyle='--', label='95%')
ax2.set_xlabel('ä¸»æˆåˆ†æ•°é‡')
ax2.set_ylabel('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax2.set_title('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('pca_variance_analysis.png', dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
pca_variance_df = pd.DataFrame({
    'Principal_Component': [f'PC{i + 1}' for i in range(len(explained_variance))],
    'Explained_Variance_Ratio': explained_variance,
    'Cumulative_Explained_Variance': cumulative_variance
})
pca_variance_df.to_csv('pca_variance_analysis.csv', encoding='utf-8-sig', index=False)


# PCAé™ç»´å†³ç­–
n_features = len(feature_cols)
n_components_80 = np.where(cumulative_variance >= 0.8)[0][0] + 1
n_components_90 = np.where(cumulative_variance >= 0.9)[0][0] + 1
n_components_95 = np.where(cumulative_variance >= 0.95)[0][0] + 1

print(f"åŸå§‹ç‰¹å¾æ•°: {n_features}")
print(f"è§£é‡Š80%æ–¹å·®éœ€è¦: {n_components_80} ä¸ªä¸»æˆåˆ†")
print(f"è§£é‡Š90%æ–¹å·®éœ€è¦: {n_components_90} ä¸ªä¸»æˆåˆ†")
print(f"è§£é‡Š95%æ–¹å·®éœ€è¦: {n_components_95} ä¸ªä¸»æˆåˆ†")

# é™ç»´å†³ç­–
use_pca = False
if n_features > 10 and n_components_90 < n_features * 0.7:
    use_pca = True
    optimal_components = n_components_90
    print(f"\nâœ“ å»ºè®®ä½¿ç”¨PCAé™ç»´ï¼Œä¿ç•™{optimal_components}ä¸ªä¸»æˆåˆ†")

    pca = PCA(n_components=optimal_components)
    X_final = pd.DataFrame(pca.fit_transform(X_scaled),
                           columns=[f'PC{i + 1}' for i in range(optimal_components)])
else:
    print(f"\nâœ“ ä¸å»ºè®®ä½¿ç”¨PCAé™ç»´ï¼Œä¿æŒåŸå§‹ç‰¹å¾")
    X_final = X_scaled

print(f"æœ€ç»ˆç‰¹å¾ç»´åº¦: {X_final.shape}")

# 6. æ•°æ®é›†åˆ’åˆ†
print("\n6. æ•°æ®é›†åˆ’åˆ†")
print("-" * 50)

# ç¡®ä¿ X_final å’Œ y_final å®šä¹‰ä¸€è‡´
if 'X_clean' in locals() and 'y_clean' in locals():
    X_final = X_clean
    y_final = y_clean
else:
    X_final = X
    y_final = y

# æ£€æŸ¥å¹¶ç¡®ä¿æ ·æœ¬æ•°é‡ä¸€è‡´
print(f"æ£€æŸ¥æ•°æ®é›†: X_finalå½¢çŠ¶: {X_final.shape}, y_finalé•¿åº¦: {len(y_final)}")

if len(X_final) != len(y_final):
    print(f"âš ï¸ å‘ç°æ ·æœ¬æ•°ä¸ä¸€è‡´ï¼X_final: {len(X_final)}, y_final: {len(y_final)}")

    # æ–¹æ³•1: å–ä¸¤è€…çš„äº¤é›† (æ¨è)
    common_indices = X_final.index.intersection(y_final.index) if hasattr(y_final, 'index') else None

    if common_indices is not None and len(common_indices) > 0:
        print(f"ä½¿ç”¨ç´¢å¼•äº¤é›†: {len(common_indices)} ä¸ªæ ·æœ¬")
        X_final = X_final.loc[common_indices]
        y_final = y_final.loc[common_indices]
    else:
        # æ–¹æ³•2: å–å‰Nä¸ªæ ·æœ¬ (å¤‡é€‰)
        min_samples = min(len(X_final), len(y_final))
        print(f"å¯¹é½åˆ°ç›¸åŒé•¿åº¦: {min_samples} ä¸ªæ ·æœ¬")
        X_final = X_final.iloc[:min_samples] if hasattr(X_final, 'iloc') else X_final[:min_samples]
        y_final = y_final.iloc[:min_samples] if hasattr(y_final, 'iloc') else y_final[:min_samples]

# é‡ç½®ç´¢å¼•ç¡®ä¿ä¸€è‡´æ€§
X_final = X_final.reset_index(drop=True) if hasattr(X_final, 'reset_index') else X_final
if hasattr(y_final, 'reset_index'):
    y_final = y_final.reset_index(drop=True)

# å†æ¬¡æ£€æŸ¥ä¸€è‡´æ€§
print(f"å¯¹é½åæ•°æ®: X_finalå½¢çŠ¶: {X_final.shape}, y_finalé•¿åº¦: {len(y_final)}")
assert len(X_final) == len(y_final), "æ•°æ®é›†æ ·æœ¬æ•°ä»ä¸ä¸€è‡´!"

#ä¿å­˜å¤„ç†ä¹‹åçš„æ•°æ®åˆ°csv
X_final.to_csv('final_features.csv', encoding='utf-8-sig', index=False)
y_final.to_csv('final_target.csv', encoding='utf-8-sig', index=False)
print("å·²åˆ†åˆ«ä¿å­˜æœ€ç»ˆç‰¹å¾å’Œç›®æ ‡å˜é‡åˆ° CSV æ–‡ä»¶")
print(X_final.head())
print(y_final.head())
#æœ€ç»ˆç‰¹å¾å’Œç›®æ ‡å˜é‡åˆ°ä¸€ä¸ª CSV æ–‡ä»¶
final_data = pd.concat([X_final, y_final.reset_index(drop=True)], axis=1)
final_data.to_csv('final_dataset.csv', encoding='utf-8-sig', index=False)
print("å·²ä¿å­˜æœ€ç»ˆæ•°æ®é›†åˆ° CSV æ–‡ä»¶")
# ä½¿ç”¨åˆ†å±‚æŠ½æ ·ç¡®ä¿ç±»åˆ«åˆ†å¸ƒä¸€è‡´
# ç„¶åå†è¿›è¡Œåˆ’åˆ†
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_final, y_final, test_size=0.2, random_state=42, stratify=y_final)

print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}")
print(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")
print(f"è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ: {pd.Series(y_train).value_counts().to_dict()}")
print(f"æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: {pd.Series(y_test).value_counts().to_dict()}")


# 7. æœºå™¨å­¦ä¹ æ¨¡å‹å®šä¹‰
print("\n7. æœºå™¨å­¦ä¹ æ¨¡å‹å®šä¹‰")
print("-" * 50)

# å®šä¹‰13ç§æœºå™¨å­¦ä¹ æ¨¡å‹
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'SGD Classifier': SGDClassifier(max_iter=1000, tol=1e-3),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(n_estimators=100),
    'AdaBoost': AdaBoostClassifier(n_estimators=100),
    'Extra Trees': ExtraTreesClassifier(n_estimators=100),
    'Support Vector Machine': SVC(probability=True),
    'Gaussian Naive Bayes': GaussianNB(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Multi-layer Perceptron': MLPClassifier(max_iter=1000),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    'lightGBM': LGBMClassifier()
}

print(f"å®šä¹‰äº†{len(models)}ç§æœºå™¨å­¦ä¹ æ¨¡å‹")

# 8. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
print("\n8. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°")
print("-" * 50)

# å­˜å‚¨ç»“æœ
results = {}
cv_scores = {}
predictions = {}

# 5æŠ˜äº¤å‰éªŒè¯
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹...")
for name, model in models.items():
    print(f"è®­ç»ƒ {name}...", end=' ')

    try:
        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train, y_train)

        # é¢„æµ‹
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') and len(
            np.unique(y_final)) == 2 else None

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')

        # äº¤å‰éªŒè¯
        cv_score = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')

        # å­˜å‚¨ç»“æœ
        results[name] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'cv_mean': cv_score.mean(),
            'cv_std': cv_score.std()
        }

        cv_scores[name] = cv_score
        predictions[name] = {'y_pred': y_pred, 'y_pred_proba': y_pred_proba}

        print("âœ“")

    except Exception as e:
        print(f"âœ— é”™è¯¯: {str(e)}")
        continue

import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc, RocCurveDisplay
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score)

# ------------- 2. è®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼Œä¿å­˜åˆ†æ•° -------------------
print("\n=== æ¨¡å‹è®­ç»ƒå¹¶ç¼“å­˜é¢„æµ‹æ¦‚ç‡ ===")
y_test_bin = label_binarize(y_final, classes=sorted(y_final.unique()))
n_classes = y_test_bin.shape[1]

# é‡æ–°åˆ‡åˆ†ï¼ˆä¿æŒä¸å‰é¢ä¸€è‡´ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X_final, y_final, test_size=0.2, random_state=42, stratify=y_final)
y_test_bin = label_binarize(y_test, classes=sorted(y_final.unique()))

model_scores = {}  # å­˜AUC
model_fpr_tpr = {}  # å­˜æ›²çº¿ (fpr, tpr)
skip_models = []  # æ— æ³•ç”»ROCçš„æ¨¡å‹

for name, model in models.items():
    try:
        model.fit(X_train, y_train)

        # å–å¾—â€œè¿ç»­è¾“å‡ºâ€ä»¥ç»˜åˆ¶ ROC
        if hasattr(model, "predict_proba"):
            y_score = model.predict_proba(X_test)  # shape = (n_samples, n_classes)
        elif hasattr(model, "decision_function"):
            y_score = model.decision_function(X_test)
            # è‹¥ decision_function åªç»™ (n_samples,)ï¼Œéœ€è½¬æˆ (n_samples, n_classes)
            if y_score.ndim == 1:
                # äºŒåˆ†ç±»æ‰ä¼šé‡åˆ°ï¼Œä½†ä¸ºäº†ä»£ç å¥å£®æ€§ï¼š
                y_score = np.column_stack([-y_score, y_score])
        else:
            print(f"âš ï¸  {name} æ—¢æ—  predict_proba ä¹Ÿæ—  decision_functionï¼Œè·³è¿‡ ROCã€‚")
            skip_models.append(name)
            continue

        # è®¡ç®— micro-average & macro-average AUC
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        # micro
        fpr["micro"], tpr["micro"], _ = roc_curve(
            y_test_bin.ravel(), y_score.ravel()
        )
        roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

        # macro
        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
        mean_tpr /= n_classes
        fpr["macro"] = all_fpr
        tpr["macro"] = mean_tpr
        roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

        model_scores[name] = roc_auc
        model_fpr_tpr[name] = (fpr, tpr)
        print(f"âœ“ {name} - macro AUC: {roc_auc['macro']:.3f}")

    except Exception as e:
        print(f"âœ— {name} è®­ç»ƒæˆ–é¢„æµ‹å‡ºé”™: {e}")
        skip_models.append(name)
        continue


# ------------- 3. ç»˜åˆ¶ä¸€å¼ å¤§å›¾ï¼šmacro-average ROC -----------------
print("\n=== ç»˜åˆ¶ ROC æ›²çº¿ ===")
plt.figure(figsize=(10, 8))
colors = cycle(plt.cm.tab20.colors)  # è‡³å°‘ 20 ç§é¢œè‰²

for (name, color) in zip(model_scores.keys(), colors):
    fpr, tpr = model_fpr_tpr[name]
    auc_val = model_scores[name]["macro"]
    plt.plot(
        fpr["macro"],
        tpr["macro"],
        color=color,
        lw=2,
        label=f"{name} (AUC = {auc_val:.3f})"
    )

# å¯¹è§’çº¿
plt.plot([0, 1], [0, 1], "k--", lw=1)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.title("Macro-Average ROC Curves (3-class, 12 Models)", fontsize=14, fontweight="bold")
plt.legend(loc="lower right", fontsize=8)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("all_models_macro_roc.png", dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
macro_roc_data = []
for name in model_scores.keys():
    fpr, tpr = model_fpr_tpr[name]
    for fp, tp in zip(fpr["macro"], tpr["macro"]):
        macro_roc_data.append({
            'Model': name,
            'FPR': fp,
            'TPR': tp,
            'AUC': model_scores[name]['macro']
        })
macro_roc_df = pd.DataFrame(macro_roc_data)
macro_roc_df.to_csv('all_models_macro_roc_data.csv', encoding='utf-8-sig', index=False)


# ------------- 4. ï¼ˆå¯é€‰ï¼‰å†ç”» micro-average -----------------
plt.figure(figsize=(10, 8))
colors = cycle(plt.cm.Dark2.colors)

for (name, color) in zip(model_scores.keys(), colors):
    fpr, tpr = model_fpr_tpr[name]
    auc_val = model_scores[name]["micro"]
    plt.plot(
        fpr["micro"],
        tpr["micro"],
        color=color,
        lw=2,
        label=f"{name} (AUC = {auc_val:.3f})"
    )

plt.plot([0, 1], [0, 1], "k--", lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.title("Micro-Average ROC Curves (3-class, 12 Models)", fontsize=14, fontweight="bold")
plt.legend(loc="lower right", fontsize=8)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("all_models_micro_roc.png", dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
micro_roc_data = []
for name in model_scores.keys():
    fpr, tpr = model_fpr_tpr[name]
    for fp, tp in zip(fpr["micro"], tpr["micro"]):
        micro_roc_data.append({
            'Model': name,
            'FPR': fp,
            'TPR': tp,
            'AUC': model_scores[name]['micro']
        })
micro_roc_df = pd.DataFrame(micro_roc_data)
micro_roc_df.to_csv('all_models_micro_roc_data.csv', encoding='utf-8-sig', index=False)


# ------------- 5. ç®€å•æ±‡æ€»è¡¨ -----------------
print("\n=== ä¸»è¦ AUC æ±‡æ€» (macro / micro) ===")
for name, scores in model_scores.items():
    print(f"{name:25s}  Macro AUC: {scores['macro']:.3f}  |  Micro AUC: {scores['micro']:.3f}")

if skip_models:
    print("\nâš ï¸  ä»¥ä¸‹æ¨¡å‹å› ç¼ºå°‘è¿ç»­è¾“å‡ºè€Œæœªç»˜åˆ¶ ROCï¼š", ", ".join(skip_models))

# 9. ç»“æœå¯è§†åŒ–å¯¹æ¯”
print("\n9. æ¨¡å‹æ€§èƒ½å¯è§†åŒ–å¯¹æ¯”")
print("-" * 50)

# åˆ›å»ºç»“æœDataFrame
results_df = pd.DataFrame(results).T
print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨:")
print(results_df.round(4))

# æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–
fig, axes = plt.subplots(2, 3, figsize=(20, 12))
axes = axes.ravel()

metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'cv_mean']
metric_names = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°', 'äº¤å‰éªŒè¯å‡å€¼']

for i, (metric, name) in enumerate(zip(metrics, metric_names)):
    if i < len(axes):
        data_to_plot = results_df[metric].sort_values(ascending=False)
        bars = axes[i].bar(range(len(data_to_plot)), data_to_plot.values, color='skyblue', alpha=0.8)
        axes[i].set_title(f'{name} å¯¹æ¯”')
        axes[i].set_xticks(range(len(data_to_plot)))
        axes[i].set_xticklabels(data_to_plot.index, rotation=45, ha='right')
        axes[i].set_ylabel(name)
        axes[i].grid(True, alpha=0.3)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for j, bar in enumerate(bars):
            height = bar.get_height()
            axes[i].text(bar.get_x() + bar.get_width() / 2., height + 0.001,
                         f'{height:.3f}', ha='center', va='bottom', fontsize=8)

# äº¤å‰éªŒè¯åˆ†æ•°ç®±çº¿å›¾
if len(cv_scores) > 0:
    axes[5].boxplot([cv_scores[name] for name in results.keys()],
                    labels=[name for name in results.keys()])
    axes[5].set_title('äº¤å‰éªŒè¯åˆ†æ•°åˆ†å¸ƒ')
    axes[5].set_xticklabels(results.keys(), rotation=45, ha='right')
    axes[5].set_ylabel('å‡†ç¡®ç‡')
    axes[5].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('model_performance_comparison.png', dpi=300)
plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
results_df.to_csv('model_performance_comparison.csv', encoding='utf-8-sig')
cv_scores_df = pd.DataFrame({name: scores for name, scores in cv_scores.items()})
cv_scores_df.to_csv('model_cross_validation_scores.csv', encoding='utf-8-sig', index=False)

# 10. ç»¼åˆæ’åå’Œæœ€ä¼˜æ¨¡å‹é€‰æ‹©
print("\n10. ç»¼åˆæ’åå’Œæœ€ä¼˜æ¨¡å‹é€‰æ‹©")
print("-" * 50)

# è®¡ç®—ç»¼åˆå¾—åˆ†
weights = {
    'accuracy': 0.3,
    'precision': 0.2,
    'recall': 0.2,
    'f1_score': 0.2,
    'cv_mean': 0.1
}

results_df['ç»¼åˆå¾—åˆ†'] = 0
for metric, weight in weights.items():
    # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
    normalized = (results_df[metric] - results_df[metric].min()) / (results_df[metric].max() - results_df[metric].min())
    results_df['ç»¼åˆå¾—åˆ†'] += normalized * weight

# æ’åº
final_ranking = results_df.sort_values('ç»¼åˆå¾—åˆ†', ascending=False)

print("æœ€ç»ˆæ¨¡å‹æ’å:")
print("=" * 70)
ranking_display = final_ranking[['accuracy', 'precision', 'recall', 'f1_score', 'cv_mean', 'ç»¼åˆå¾—åˆ†']].round(4)
for i, (name, row) in enumerate(ranking_display.iterrows(), 1):
    print(f"{i:2d}. {name:15s} | ç»¼åˆå¾—åˆ†: {row['ç»¼åˆå¾—åˆ†']:.4f} | "
          f"å‡†ç¡®ç‡: {row['accuracy']:.4f} | F1: {row['f1_score']:.4f} | "
          f"CV: {row['cv_mean']:.4f}Â±{final_ranking.loc[name, 'cv_std']:.4f}")

# é€‰æ‹©æœ€ä¼˜æ¨¡å‹
best_model_name = final_ranking.index[0]
best_model = models[best_model_name]
best_predictions = predictions[best_model_name]

print(f"\nğŸ† æœ€ä¼˜æ¨¡å‹: {best_model_name}")
print(f"   ç»¼åˆå¾—åˆ†: {final_ranking.iloc[0]['ç»¼åˆå¾—åˆ†']:.4f}")
print(f"   å‡†ç¡®ç‡: {final_ranking.iloc[0]['accuracy']:.4f}")
print(f"   F1åˆ†æ•°: {final_ranking.iloc[0]['f1_score']:.4f}")

# 11. æ¨¡å‹è¯¦ç»†åˆ†æ
print("\n11. æ¨¡å‹è¯¦ç»†åˆ†æ")
print("-" * 50)
#12ç§æ¨¡å‹ä¸­çš„æ··æ·†çŸ©é˜µ
for name in results.keys():
    y_pred = predictions[name]['y_pred']
    y_pred_proba = predictions[name]['y_pred_proba']

    print(f"\nğŸ” {name} æ¨¡å‹è¯¦ç»†åˆ†æ")

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} - æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig(f'{name}_confusion_matrix.png', dpi=300)
    plt.show()
#ä¿å­˜ç»˜å›¾çš„æ•°æ®åˆ°csv
    cm_df = pd.DataFrame(cm, index=np.unique(y_final), columns=np.unique(y_final))
    cm_df.to_csv(f'{name}_confusion_matrix.csv', encoding='utf-8-sig')
    # åˆ†ç±»æŠ¥å‘Š
    report = classification_report(y_test, y_pred, output_dict=True)
    report_df = pd.DataFrame(report).T
    print(f"\nåˆ†ç±»æŠ¥å‘Š:\n{report_df.round(4)}")
    report_df.to_csv(f'{name}_classification_report.csv', encoding='utf-8-sig')

print("\n" + "=" * 80)
print("ğŸ‰ å®Œæ•´çš„æœºå™¨å­¦ä¹ Pipelineå·²å®Œæˆ!")
print("ğŸ” åŒ…å«EDAåˆ†æ â†’ æ•°æ®é¢„å¤„ç† â†’ æ¨¡å‹å¯¹æ¯” â†’ ç»“æœåˆ†æ")
print("ğŸ“Š ç”Ÿæˆäº†è¯¦ç»†çš„å¯è§†åŒ–å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š")
print("=" * 80)
#æµ‹è¯•é›†é¢„æµ‹ç»“æœï¼Œè®¡ç®—å„ä¸ªç±»åˆ«æ¦‚ç‡
y_test_pred = best_model.predict(X_test)
y_test_pred_proba = best_model.predict_proba(X_test) if hasattr(best_model, 'predict_proba') else None
test_results_df = pd.DataFrame({
    'çœŸå®æ ‡ç­¾': y_test,
    'é¢„æµ‹æ ‡ç­¾': y_test_pred
})
if y_test_pred_proba is not None:
    for i in range(y_test_pred_proba.shape[1]):
        test_results_df[f'ç±»åˆ«_{i}_æ¦‚ç‡'] = y_test_pred_proba[:, i]


test_results_df.to_csv('best_model_test_predictions.csv', encoding='utf-8-sig', index=False)
print(test_results_df.head())
print("æµ‹è¯•é›†é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° 'best_model_test_predictions.csv'")



# 12. æ¨¡å‹ä¿å­˜å’Œæ–°æ•°æ®é¢„æµ‹
print("\n12. æ¨¡å‹ä¿å­˜å’Œæ–°æ•°æ®é¢„æµ‹")
print("-" * 50)

# =================================================================
# ä¿å­˜æƒé‡å‚æ•°å’Œé¢„å¤„ç†å™¨
# =================================================================
import joblib
import os

try:
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    save_dir = "models"
    os.makedirs(save_dir, exist_ok=True)

    # ä½¿ç”¨f-stringç®€åŒ–æ–‡ä»¶åç”Ÿæˆ
    joblib.dump(imputer, f"{save_dir}/{num}_imputer.pkl")
    joblib.dump(scaler, f"{save_dir}/{num}_scaler.pkl")
    print("âœ“ é¢„å¤„ç†å™¨ (imputer, scaler) å·²ä¿å­˜ã€‚")

    # ä¿å­˜PCAé…ç½®
    pca_config = {
        'use_pca': use_pca,
        'feature_cols': feature_cols
    }

    if use_pca:
        joblib.dump(pca, f"{save_dir}/{num}_pca.pkl")
        pca_config['optimal_components'] = optimal_components
        print("âœ“ PCA å¯¹è±¡å·²ä¿å­˜ã€‚")

    joblib.dump(pca_config, f"{save_dir}/{num}_pca_config.pkl")
    print("âœ“ PCA é…ç½®å·²ä¿å­˜ã€‚")
    # ä¿ç•™æœ€ä¼˜æ¨¡å‹çš„æƒé‡å‚æ•°
    joblib.dump(best_model, f"{save_dir}/{num}_best_model_{best_model_name.replace(' ', '_')}.pkl")
    print(f"âœ“ æœ€ä¼˜æ¨¡å‹ ({best_model_name}) å·²ä¿å­˜ã€‚")

except Exception as e:
    print(f"ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")








